{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhangchao\\.conda\\envs\\olive\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda51c4914384de89440bcfc36a94efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.8081283569336, 70.60625457763672, 71.066162109375, 139.8637237548828, 53.41142654418945]\n",
      "82.95113906860351\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "perplexity = evaluate.load(\"perplexity\", module_type=\"measurement\")\n",
    "input_texts = [\"Hello I'm a model model.\", \"Hello I'm a world model.\", \"Hello I'm a data model.\", \"Hello I'm a flight model.\", \"Hello I'm a business model.\" ]\n",
    "results = perplexity.compute(model_id='gpt2',\n",
    "                             add_start_token=False,\n",
    "                             data=input_texts)\n",
    "\n",
    "print(results[\"perplexities\"])\n",
    "print(results[\"mean_perplexity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70.60625457763672, 61.20323944091797, 114.32771301269531, 160.382080078125, 59.99957275390625]\n",
      "93.30377197265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts2 = [\"Hello I'm a world model.\", \"Hello I'm a real model.\", \"Hello I'm a life model.\", \"Hello I'm a Hello model.\", \"Hello I'm a physical model.\" ]\n",
    "results2 = perplexity.compute(model_id='gpt2',\n",
    "                             add_start_token=False,\n",
    "                             data=input_texts2)\n",
    "\n",
    "print(results2[\"perplexities\"])\n",
    "print(results2[\"mean_perplexity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhangchao\\.conda\\envs\\olive\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.619503021240234, 41.629066467285156, 64.31881713867188, 35.78849411010742, 76.13717651367188]\n",
      "53.098611450195314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_texts3 = [\"Hello I'm a fashion model.\", \"Hello I'm a professional model.\", \"Hello I'm a male model.\", \"Hello I'm a role model.\", \"Hello I'm a fitness model.\" ]\n",
    "results3 = perplexity.compute(model_id='gpt2',\n",
    "                             add_start_token=False,\n",
    "                             data=input_texts3)\n",
    "\n",
    "print(results3[\"perplexities\"])\n",
    "print(results3[\"mean_perplexity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.14917755126953]\n",
      "39.14917755126953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results4 = perplexity.compute(model_id='gpt2',\n",
    "                             add_start_token=False,\n",
    "                             data=[\"Anarchism is a political philosophy and movement that is sceptical of authority and rejects all involuntary, coercive forms of hierarchy.\"])\n",
    "\n",
    "print(results4[\"perplexities\"])\n",
    "print(results4[\"mean_perplexity\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
